scraper:
  source_url: "https://example-weather-website.com/historical"
  # If the site offers a JSON API, you could point here instead.
  output_path_raw: "./data/raw/historical_weather.csv"

processing:
  input_path_raw: "./data/raw/historical_weather.csv"
  output_path_clean: "./data/clean/historical_weather_clean.csv"
  drop_columns:
    - "UnnecessaryColumn1"
    - "UnnecessaryColumn2"
  date_column: "date"
  fillna_method: "ffill"      # forward-fill missing values (example)
  features_to_engineer:
    - "day_of_year"
    - "month"
    - "year"

database:
  user: "postgres"
  password:  # ***do NOT commit a real password!***
  host: "postgres"   # Hostname as seen by Docker service (service name in docker-compose)
  port: 5432
  db_name: "weather_db"

model:
  target_column: "temperature_max"
  test_size: 0.2
  random_state: 42
  model_output_path: "./data/models/weather_model.pkl"

app:
  host: "0.0.0.0"
  port: 8050
  debug: False

docker:
  postgres_image: "postgres:13-alpine"
  app_image_name: "weather_app"
  port_mapping:
    - "8050:8050"   # Map host:container
